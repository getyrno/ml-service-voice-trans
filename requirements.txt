fastapi==0.115.2
uvicorn[standard]==0.30.1

python-multipart==0.0.9
ffmpeg-python==0.2.0

# ВАЖНО: связка под CUDA 12.3 + cuDNN 9
# faster-whisper использует CTranslate2, который с 4.5.0 работает с cuDNN 9 
faster-whisper==1.1.0
ctranslate2==4.6.2

requests==2.31.0
httpx==0.27.2
pytest==8.3.2

# faster-whisper и torch пока живут на NumPy 1.x
numpy<2

transformers==4.47.0
sentencepiece
hydra-core
omegaconf

redis

# На будущее: если вернёшь VAD через ONNX — CPU-версия onnxruntime,
# чтобы не упираться в очередную матрицу CUDA/cuDNN
onnxruntime==1.19.2
