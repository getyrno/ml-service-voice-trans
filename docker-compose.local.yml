services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  api:
    build:
      context: .
      dockerfile: Dockerfile.m1
    container_name: ml-service-voice-trans-local
    restart: unless-stopped
    ports:
      - "8000:8000"

    environment:
      TZ: Europe/Moscow
      ENV_NAME: local-dev
      CLIENT_NAME: local-pc

      # ===== Async Jobs Config =====
      REDIS_URL: redis://redis:6379/0
      # Если оркестратор запущен локально на порту 9000:
      ORCHESTRATOR_JOB_URL: http://host.docker.internal:9000/events/transcribe/job
      UPLOAD_DIR: /uploads

      # ===== STT Провайдер =====
      # Выбор: "whisper" или "gigaam"
      STT_PROVIDER: whisper

      # ===== Whisper настройки =====
      WHISPER_MODEL: small

      # ===== GigaAM настройки =====
      GIGAAM_MODEL_VARIANT: e2e_rnnt
      # HuggingFace токен (нужен для GigaAM/pyannote) - берется из .env файла
      HF_TOKEN: ${HF_TOKEN}

      # ===== A/B тестирование =====
      # 0 = только Whisper, 100 = только GigaAM
      STT_AB_GIGAAM_PERCENT: "0"

    # Кеш моделей и загрузки
    volumes:
      - ./uploads:/uploads
      - ~/.cache/huggingface:/root/.cache/huggingface
      - ~/.cache/whisper:/root/.cache/whisper

    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
